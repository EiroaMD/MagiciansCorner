{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Basic_Unet.ipynb","provenance":[{"file_id":"1XZjr-FwHYb03d5g6YgIvNxKzJ0jxPgz8","timestamp":1574356508639},{"file_id":"1Q7nN0MWN9tv9X6yPvm28-4bizTCoHPw0","timestamp":1572903615354},{"file_id":"1gZisPrYus_2Md_kUC8trCj1z1ML4hOT6","timestamp":1572902899476},{"file_id":"1wVpnLV_o5mO_IEFURnikfQryxWd6Q5zc","timestamp":1572902659682}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"f-7VxpFXbhM8","colab_type":"text"},"source":["Cell 1 loads up all the libraries we are using. In the first lessons, we used fastAI, while in this one we use Tensorflow with Keras. Both of these are large libraries, and its designers decided to allow programmers to load only the pieces that are relevant, which is what the 'from keras.XXX import YYY' lines do--they load just the partrt of Keras (or other library) that we want. This makes the load time faster and the final running program smaller.\n","\n","The second half of this cell does the familiar step of loading the data sets that I have prepared, which in this case are a series of abdominal CTs as well as hand-traced masks of the Pancreas, courtesy of The Cancer Image Archive: http://TheCancerImageArchive...."]},{"cell_type":"code","metadata":{"id":"ngjE5zA0F1PE","colab_type":"code","outputId":"fa8eb407-d541-441b-dfd3-211458647520","executionInfo":{"status":"ok","timestamp":1574356120057,"user_tz":360,"elapsed":42898,"user":{"displayName":"Brad Erickson","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGtI8-0w18OuIRYxbe54rj6-8_71YZ04mntCh7z4M=s64","userId":"16160187475894979440"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#Cell 1\n","\n","!pip install -q keras\n","!pip install natsort\n","import numpy as np\n","import numpy.ma as ma\n","import os\n","import shutil\n","import tensorflow as tf\n","from keras.models import Model, load_model\n","from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, Dense, Dropout, Activation, Flatten, BatchNormalization, Reshape\n","from keras.engine.topology import Layer\n","\n","from keras.layers.merge import concatenate, add\n","from keras.layers.core import Lambda\n","from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n","from keras import backend as K\n","from keras.utils.generic_utils import get_custom_objects\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import imageio\n","from natsort import natsorted\n","import random\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","\n","!rm -rf ./MC4-TensorflowUNet\n","\n","!rm -rf trainimages\n","!mkdir trainimages\n","!rm -rf trainmasks\n","!mkdir trainmasks\n","\n","!rm -rf validationimages\n","!mkdir validationimages\n","!rm -rf validationmasks\n","!mkdir validationmasks\n","\n","!rm -rf testimages\n","!mkdir testimages\n","!rm -rf testmasks\n","!mkdir testmasks\n","\n","\n","!rm *.zip\n","#Zip files 1 & 2 have the data used for training\n","!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1pH5FgRRUPCmzbCszm101vAyTVe7Ufs60' -O ./Pt1.zip\n","!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1V4zAE19E1kLUK0Z0YIWNpMq0K8lOARtu' -O ./Pt2.zip\n","\n","!unzip -q -o \"./Pt1.zip\"\n","!unzip -q -o \"./Pt2.zip\"\n","!mv *-Mask.jpg ./trainmasks\n","!mv *.jpg ./trainimages\n","\n","# Zip3 is for validation\n","!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=18mVgpUeghNOHKMazHLINyjq6lPKstLJp' -O ./Pt3.zip\n","!unzip -q -o \"./Pt3.zip\"\n","!mv *-Mask.jpg ./validationmasks\n","!mv *.jpg ./validationimages\n","\n","#Part 4 is for testing\n","!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Rh53wMdhEvOOel6z2c47uPW_R72I8dLe' -O ./Pt4.zip\n","!unzip -q -o \"./Pt4.zip\"\n","!mv *-Mask.jpg ./testmasks\n","!mv *.jpg ./testimages"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: natsort in /usr/local/lib/python3.6/dist-packages (5.5.0)\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["rm: cannot remove '*.zip': No such file or directory\n","--2019-11-21 17:08:15--  https://docs.google.com/uc?export=download&id=1pH5FgRRUPCmzbCszm101vAyTVe7Ufs60\n","Resolving docs.google.com (docs.google.com)... 74.125.31.101, 74.125.31.100, 74.125.31.139, ...\n","Connecting to docs.google.com (docs.google.com)|74.125.31.101|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-0s-60-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/gdgc11m90tdpr65uiiq0ael0hn86pptp/1574352000000/16160187475894979440/*/1pH5FgRRUPCmzbCszm101vAyTVe7Ufs60?e=download [following]\n","Warning: wildcards not supported in HTTP.\n","--2019-11-21 17:08:22--  https://doc-0s-60-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/gdgc11m90tdpr65uiiq0ael0hn86pptp/1574352000000/16160187475894979440/*/1pH5FgRRUPCmzbCszm101vAyTVe7Ufs60?e=download\n","Resolving doc-0s-60-docs.googleusercontent.com (doc-0s-60-docs.googleusercontent.com)... 172.217.204.132, 2607:f8b0:400c:c15::84\n","Connecting to doc-0s-60-docs.googleusercontent.com (doc-0s-60-docs.googleusercontent.com)|172.217.204.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/zip]\n","Saving to: ‘./Pt1.zip’\n","\n","./Pt1.zip               [ <=>                ]  16.35M  97.8MB/s    in 0.2s    \n","\n","2019-11-21 17:08:22 (97.8 MB/s) - ‘./Pt1.zip’ saved [17146018]\n","\n","--2019-11-21 17:08:23--  https://docs.google.com/uc?export=download&id=1V4zAE19E1kLUK0Z0YIWNpMq0K8lOARtu\n","Resolving docs.google.com (docs.google.com)... 74.125.31.101, 74.125.31.100, 74.125.31.139, ...\n","Connecting to docs.google.com (docs.google.com)|74.125.31.101|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-0g-60-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rp899t099ggjufkl373f1pcuq4stn62v/1574352000000/16160187475894979440/*/1V4zAE19E1kLUK0Z0YIWNpMq0K8lOARtu?e=download [following]\n","Warning: wildcards not supported in HTTP.\n","--2019-11-21 17:08:24--  https://doc-0g-60-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rp899t099ggjufkl373f1pcuq4stn62v/1574352000000/16160187475894979440/*/1V4zAE19E1kLUK0Z0YIWNpMq0K8lOARtu?e=download\n","Resolving doc-0g-60-docs.googleusercontent.com (doc-0g-60-docs.googleusercontent.com)... 172.217.204.132, 2607:f8b0:400c:c15::84\n","Connecting to doc-0g-60-docs.googleusercontent.com (doc-0g-60-docs.googleusercontent.com)|172.217.204.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/zip]\n","Saving to: ‘./Pt2.zip’\n","\n","./Pt2.zip               [ <=>                ]  12.80M  --.-KB/s    in 0.05s   \n","\n","2019-11-21 17:08:24 (280 MB/s) - ‘./Pt2.zip’ saved [13422724]\n","\n","--2019-11-21 17:08:27--  https://docs.google.com/uc?export=download&id=18mVgpUeghNOHKMazHLINyjq6lPKstLJp\n","Resolving docs.google.com (docs.google.com)... 74.125.31.101, 74.125.31.100, 74.125.31.138, ...\n","Connecting to docs.google.com (docs.google.com)|74.125.31.101|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-08-60-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/c3gbjquka7ou36ec9otmvh93b8vmo7ot/1574352000000/16160187475894979440/*/18mVgpUeghNOHKMazHLINyjq6lPKstLJp?e=download [following]\n","Warning: wildcards not supported in HTTP.\n","--2019-11-21 17:08:32--  https://doc-08-60-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/c3gbjquka7ou36ec9otmvh93b8vmo7ot/1574352000000/16160187475894979440/*/18mVgpUeghNOHKMazHLINyjq6lPKstLJp?e=download\n","Resolving doc-08-60-docs.googleusercontent.com (doc-08-60-docs.googleusercontent.com)... 172.217.204.132, 2607:f8b0:400c:c15::84\n","Connecting to doc-08-60-docs.googleusercontent.com (doc-08-60-docs.googleusercontent.com)|172.217.204.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/zip]\n","Saving to: ‘./Pt3.zip’\n","\n","./Pt3.zip               [ <=>                ]   3.79M  --.-KB/s    in 0.02s   \n","\n","2019-11-21 17:08:32 (249 MB/s) - ‘./Pt3.zip’ saved [3978825]\n","\n","--2019-11-21 17:08:35--  https://docs.google.com/uc?export=download&id=1Rh53wMdhEvOOel6z2c47uPW_R72I8dLe\n","Resolving docs.google.com (docs.google.com)... 74.125.31.101, 74.125.31.100, 74.125.31.138, ...\n","Connecting to docs.google.com (docs.google.com)|74.125.31.101|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-0o-60-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7he32hj0n7on2kdhvrmjt88qmj104a1o/1574352000000/16160187475894979440/*/1Rh53wMdhEvOOel6z2c47uPW_R72I8dLe?e=download [following]\n","Warning: wildcards not supported in HTTP.\n","--2019-11-21 17:08:37--  https://doc-0o-60-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7he32hj0n7on2kdhvrmjt88qmj104a1o/1574352000000/16160187475894979440/*/1Rh53wMdhEvOOel6z2c47uPW_R72I8dLe?e=download\n","Resolving doc-0o-60-docs.googleusercontent.com (doc-0o-60-docs.googleusercontent.com)... 172.217.204.132, 2607:f8b0:400c:c15::84\n","Connecting to doc-0o-60-docs.googleusercontent.com (doc-0o-60-docs.googleusercontent.com)|172.217.204.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2044499 (1.9M) [application/zip]\n","Saving to: ‘./Pt4.zip’\n","\n","./Pt4.zip           100%[===================>]   1.95M  --.-KB/s    in 0.009s  \n","\n","2019-11-21 17:08:37 (223 MB/s) - ‘./Pt4.zip’ saved [2044499/2044499]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Lwe2tW_S5I0t","colab_type":"text"},"source":["#Data Wrangling\n","Here we organize the data into training, validation and testing sets, with each having an image and mask, so 6 directories total. I started with the TCIA-Pancreas data set, which has hand-traced contours of the pancreas.\n","I took each image that had some pancreas traced, applied 400/40 W/L settings, converted to 8 bits, and then cropped to the central 256x256 (just to reduce memory demands). The mask is also cropped to match, and is either o or 1.\n","THese are then loaded into the respective memory arrays."]},{"cell_type":"markdown","metadata":{"id":"Rg-8caamcSTp","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"iiNnuEKhkS0t","colab_type":"code","outputId":"747708b7-8124-4820-811e-95e9db55fdda","executionInfo":{"status":"ok","timestamp":1574356123662,"user_tz":360,"elapsed":46495,"user":{"displayName":"Brad Erickson","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGtI8-0w18OuIRYxbe54rj6-8_71YZ04mntCh7z4M=s64","userId":"16160187475894979440"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Cell 2\n","\n","train_X = []\n","train_Y = []\n","val_X = []\n","val_Y = []\n","test_X = []\n","test_Y = []\n","\n","im_list = natsorted(os.listdir('./trainimages'))\n","for f in im_list:\n","  pth = './trainimages/' + f \n","  img = imageio.imread(pth)\n","  train_X.append(np.array(img))\n","train_X = np.array(train_X)\n","train_X = train_X/255\n","train_X = train_X[..., np.newaxis]\n","\n","im_list = natsorted(os.listdir('./trainmasks'))\n","for f in im_list:\n","  pth = './trainmasks/' + f \n","  img = imageio.imread(pth)\n","  train_Y.append(np.array(img))\n","train_Y = np.array(train_Y)\n","train_Y = (train_Y > 0).astype(np.float32)\n","train_Y = train_Y[..., np.newaxis]\n","\n","im_list = natsorted(os.listdir('./validationimages'))\n","for f in im_list:\n","  pth = './validationimages/' + f \n","  img = imageio.imread(pth)\n","  val_X.append(np.array(img))\n","val_X = np.array(val_X)\n","val_X = val_X/255\n","val_X = val_X[..., np.newaxis]\n","\n","im_list = natsorted(os.listdir('./validationmasks'))\n","for f in im_list:\n","  pth = './validationmasks/' + f \n","  img = imageio.imread(pth)\n","  val_Y.append(np.array(img))\n","val_Y = np.array(val_Y)\n","val_Y = (val_Y > 0).astype(np.float32)\n","val_Y = val_Y[..., np.newaxis]\n","\n","im_list = natsorted(os.listdir('./testimages'))\n","for f in im_list:\n","  pth = './testimages/' + f \n","  img = imageio.imread(pth)\n","  test_X.append(np.array(img))\n","test_X = np.array(test_X)\n","test_X = test_X/255\n","test_X = test_X[..., np.newaxis]\n","\n","im_list = natsorted(os.listdir('./testmasks'))\n","for f in im_list:\n","  pth = './testmasks/' + f \n","  img = imageio.imread(pth)\n","  test_Y.append(np.array(img))\n","test_Y = np.array(test_Y)\n","test_Y = (test_Y > 0).astype(np.float32)\n","test_Y = test_Y[..., np.newaxis]\n","\n","print(train_X.shape[0],\"images for training,\", val_X.shape[0], \"images for validation, and\", test_X.shape[0], \"images for testing\")\n","\n","WIDTH = train_X.shape[2]\n","HEIGHT = train_X.shape[1]\n","CHANNELS = 1\n","#print ('X and Y dims are ' + str(WIDTH) + 'x' + str(HEIGHT))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["1976 images for training, 260 images for validation, and 143 images for testing\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SJu3FuYlbp-b","colab_type":"text"},"source":["#Cost Functions\n","A critical element of every machine learning algorithm is to select a good cost function. In the classificaiton problems of prior articles, we used the accuracy of predictions as the cost function. For segmentation, one potentially could compute a score for teh classification of each pixel (object or not object), but a more common metric is the Dice Similiarity Score (a.k.a. Dice Score). This essentially means the amount of overlap between the gold standard and the prediction. If they perfectly agree, the Dice Score is 1, and if there is no overlap, the score is 0. We can convert the Dice Score toa Dice Loss by subtracting it from 1. One can also convert the Dice Score to a cross-entropy function, and this can work well in some cases. Code for both is provided, and you are encouraged to try both cost functions to see the effect. Note, however, that the above can result in Dice values of zero, and we don't want to divide by zero. In fact, we don't want to divide by a small number, so we add 'smooth' to the value (in our case we are using 1) so the values of Dice actually are 1 to 2, not 0 to 1. And that means the Dice Loss will be -1 to 0, but the loss reported is the sum, so it will have a larger range.\n"]},{"cell_type":"code","metadata":{"id":"WtR4fbhhhegw","colab_type":"code","colab":{}},"source":["# Cell 3\n","def dice_coeff(y_true, y_pred):\n","    _epsilon = 10 ** -7\n","    intersections = tf.reduce_sum(y_true * y_pred)\n","    unions = tf.reduce_sum(y_true + y_pred)\n","    dice_scores = (2.0 * intersections + _epsilon) / (unions + _epsilon)\n","    return dice_scores\n","\n","def dice_loss(y_true, y_pred):\n","    loss = 1 - dice_coeff(y_true, y_pred)\n","    return loss\n","  \n","get_custom_objects().update({\"dice\": dice_loss})\n","\n","class LayerNormalization (Layer) :\n","    \n","    def call(self, x, mask=None, training=None) :\n","        axis = list (range (1, len (x.shape)))\n","        x /= K.std (x, axis = axis, keepdims = True) + K.epsilon()\n","        x -= K.mean (x, axis = axis, keepdims = True)\n","        return x\n","        \n","    def compute_output_shape(self, input_shape):\n","        return input_shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FDs_CyB-bxe6","colab_type":"text"},"source":["#Building the U-Net\n","We are finally ready to build our Network. One difference of Keras versus the previous examples of FastAI is that Keras is designed so that there is one line of code for each layer of the network (plus the setup and training/evlauation code). This means that for a moderately complex network like a ResNet34 classifier, there would be 34 lines of code. U-Nets are popular network architectures for segmentation. These get their name because of the unique way they are built: The first part produces repeated reductions in resolution as the 'important' parts of the image are retained that reflect the structures that it is trained to recognize. Typically there are 4 or 5 such reduction layers that each consist of convultions, ReLUs, and Pooling layers. Once the image is reduced to the critical components, the networks begins to reconstruct the precise margins of the critical elements by using 'skip layers'. As the resolution is stored using convolutional-transpose layers, the layers 'look' back to the layers where the resolution was reduced to try to best define the margins of the structures. See Ronneberger (Ronneberger, Olaf; Fischer, Philipp; Brox, Thomas (2015). \"U-Net: Convolutional Networks for Biomedical Image Segmentation\". arXiv:1505.04597  https://arxiv.org/pdf/1505.04597.pdf).\n","\n","There is a lot more going on that I will only provide references to (these will be covered in the future):\n","1. ReLU Activation Function: https://arxiv.org/pdf/1502.01852.pdf\n","2. Kernel Intialization (the weights loaded into the network before anything is done): https://arxiv.org/pdf/1502.01852.pdf\n","3. Transpose Convolution: https://medium.com/apache-mxnet/transposed-convolutions-explained-with-ms-excel-52d13030c7e8#Building the U-Net\n"]},{"cell_type":"code","metadata":{"id":"L-AbL6fvgPWg","colab_type":"code","colab":{}},"source":["# Cell 4\n","# this function defines the U-Net model\n","def build_model(act_fn = 'relu', init_fn = 'he_normal'): \n","# this takes in a 256 x 256 pixel image with 1 channel (gray scale)\n","    inputs = Input((256,256,1))\n","# filt is the number of filters in first layer, and each is doubled. \n","# conv is the size of the first convolution kernel. All after are 3x3\n","    filt = 6\n","    conv = 7\n","    # note we use linear function before layer normalization\n","    conv1 = Conv2D(filt, conv, activation = 'linear', padding = 'same', kernel_initializer = init_fn)(inputs)\n","    conv1 = LayerNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(filt * 2, 3, activation = act_fn, padding = 'same', kernel_initializer = init_fn)(pool1)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(filt * 4, 3, activation = 'linear', padding = 'same', kernel_initializer = init_fn)(pool2)\n","    conv3 = LayerNormalization()(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(filt * 8, 3, activation = act_fn, padding = 'same', kernel_initializer = init_fn)(pool3)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","    conv5 = Conv2D(filt * 8, 3, activation = act_fn, padding = 'same', kernel_initializer = init_fn)(pool4)\n","\n","    up6 = Conv2D(filt * 8, 2, activation = 'linear', padding = 'same', kernel_initializer = init_fn)(UpSampling2D(size = (2,2))(conv5))\n","    up6 = LayerNormalization()(up6)\n","    merge6 = concatenate([conv4,up6], axis = 3)\n","    conv6 = Conv2D(filt * 8, 3, activation = act_fn, padding = 'same', kernel_initializer = init_fn)(merge6)\n","\n","    up7 = Conv2D(filt * 4, 2, activation = act_fn, padding = 'same', kernel_initializer = init_fn)(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(filt * 4, 3, activation = act_fn, padding = 'same', kernel_initializer = init_fn)(merge7)\n","\n","    up8 = Conv2D(filt * 2, 2, activation = 'linear', padding = 'same', kernel_initializer = init_fn)(UpSampling2D(size = (2,2))(conv7))\n","    up8 = LayerNormalization()(up8)\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(filt * 2, 3, activation = act_fn, padding = 'same', kernel_initializer = init_fn)(merge8)\n","\n","    up9 = Conv2D(filt, 2, activation = act_fn, padding = 'same', kernel_initializer = init_fn)(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(filt, 3, activation = act_fn, padding = 'same', kernel_initializer = init_fn)(merge9)\n","    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","    model = Model(inputs = inputs, outputs = conv10)\n","\n","    model.compile(optimizer = Adam(lr = 1e-4), loss = 'dice', metrics=[dice_coeff])\n","    return model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lMReKXLxcCKc","colab_type":"text"},"source":["#Train it\n","Now that our model is defined, we are (finally!) ready to build it and train it. Trial and error with colab hardware (K80) has shown that a batch_size of 64 works, and that we can get reasonable results after just a few epochs (but you can train longer to get better results)"]},{"cell_type":"code","metadata":{"id":"r0rFV1kiTPcz","colab_type":"code","outputId":"c0d8eb1c-d39a-44a1-8685-e4734178cb74","executionInfo":{"status":"ok","timestamp":1574356409284,"user_tz":360,"elapsed":332103,"user":{"displayName":"Brad Erickson","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGtI8-0w18OuIRYxbe54rj6-8_71YZ04mntCh7z4M=s64","userId":"16160187475894979440"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Cell 5\n","#create the U-Net\n","model = build_model()\n","# checkpointer will save the model, in this case any time there is a better error\n","checkpointer = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n","\n","#  I get 20 seconds per epoch on colab notebook (K80s). so 50 epochs is under 20 minutes\n","# It will take more time and more examples to get pretty good results, but this gets reasonable enough considering difficulty of pancreas\n","# reduce the number of epochs if you can't wait 20 minutes. It will just reduce the accuracy of the segmentation\n","epochs = 50\n","batch_size = 64\n","results = model.fit(train_X, train_Y, validation_data=(val_X, val_Y), batch_size=batch_size, epochs=epochs, callbacks=[checkpointer])\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Train on 1976 samples, validate on 260 samples\n","Epoch 1/50\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","1976/1976 [==============================] - 15s 7ms/step - loss: 0.9552 - dice_coeff: 0.0448 - val_loss: 0.9459 - val_dice_coeff: 0.0541\n","\n","Epoch 00001: val_loss improved from inf to 0.94590, saving model to model.h5\n","Epoch 2/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.9409 - dice_coeff: 0.0591 - val_loss: 0.9231 - val_dice_coeff: 0.0769\n","\n","Epoch 00002: val_loss improved from 0.94590 to 0.92308, saving model to model.h5\n","Epoch 3/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.8828 - dice_coeff: 0.1172 - val_loss: 0.7968 - val_dice_coeff: 0.2032\n","\n","Epoch 00003: val_loss improved from 0.92308 to 0.79684, saving model to model.h5\n","Epoch 4/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.7475 - dice_coeff: 0.2525 - val_loss: 0.6721 - val_dice_coeff: 0.3279\n","\n","Epoch 00004: val_loss improved from 0.79684 to 0.67211, saving model to model.h5\n","Epoch 5/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.6565 - dice_coeff: 0.3435 - val_loss: 0.6227 - val_dice_coeff: 0.3773\n","\n","Epoch 00005: val_loss improved from 0.67211 to 0.62265, saving model to model.h5\n","Epoch 6/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.6106 - dice_coeff: 0.3894 - val_loss: 0.5999 - val_dice_coeff: 0.4001\n","\n","Epoch 00006: val_loss improved from 0.62265 to 0.59993, saving model to model.h5\n","Epoch 7/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.5709 - dice_coeff: 0.4291 - val_loss: 0.5543 - val_dice_coeff: 0.4457\n","\n","Epoch 00007: val_loss improved from 0.59993 to 0.55434, saving model to model.h5\n","Epoch 8/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.5466 - dice_coeff: 0.4534 - val_loss: 0.5412 - val_dice_coeff: 0.4588\n","\n","Epoch 00008: val_loss improved from 0.55434 to 0.54117, saving model to model.h5\n","Epoch 9/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.5213 - dice_coeff: 0.4787 - val_loss: 0.5126 - val_dice_coeff: 0.4874\n","\n","Epoch 00009: val_loss improved from 0.54117 to 0.51259, saving model to model.h5\n","Epoch 10/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.5091 - dice_coeff: 0.4909 - val_loss: 0.4984 - val_dice_coeff: 0.5016\n","\n","Epoch 00010: val_loss improved from 0.51259 to 0.49842, saving model to model.h5\n","Epoch 11/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.4901 - dice_coeff: 0.5099 - val_loss: 0.4923 - val_dice_coeff: 0.5077\n","\n","Epoch 00011: val_loss improved from 0.49842 to 0.49229, saving model to model.h5\n","Epoch 12/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.4796 - dice_coeff: 0.5204 - val_loss: 0.4764 - val_dice_coeff: 0.5236\n","\n","Epoch 00012: val_loss improved from 0.49229 to 0.47637, saving model to model.h5\n","Epoch 13/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.4636 - dice_coeff: 0.5364 - val_loss: 0.4748 - val_dice_coeff: 0.5252\n","\n","Epoch 00013: val_loss improved from 0.47637 to 0.47479, saving model to model.h5\n","Epoch 14/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.4515 - dice_coeff: 0.5485 - val_loss: 0.4754 - val_dice_coeff: 0.5246\n","\n","Epoch 00014: val_loss did not improve from 0.47479\n","Epoch 15/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.4515 - dice_coeff: 0.5485 - val_loss: 0.4600 - val_dice_coeff: 0.5400\n","\n","Epoch 00015: val_loss improved from 0.47479 to 0.46000, saving model to model.h5\n","Epoch 16/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.4422 - dice_coeff: 0.5578 - val_loss: 0.4489 - val_dice_coeff: 0.5511\n","\n","Epoch 00016: val_loss improved from 0.46000 to 0.44886, saving model to model.h5\n","Epoch 17/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.4241 - dice_coeff: 0.5759 - val_loss: 0.4445 - val_dice_coeff: 0.5555\n","\n","Epoch 00017: val_loss improved from 0.44886 to 0.44449, saving model to model.h5\n","Epoch 18/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.4124 - dice_coeff: 0.5876 - val_loss: 0.4410 - val_dice_coeff: 0.5590\n","\n","Epoch 00018: val_loss improved from 0.44449 to 0.44103, saving model to model.h5\n","Epoch 19/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.4043 - dice_coeff: 0.5957 - val_loss: 0.4403 - val_dice_coeff: 0.5597\n","\n","Epoch 00019: val_loss improved from 0.44103 to 0.44034, saving model to model.h5\n","Epoch 20/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.4020 - dice_coeff: 0.5980 - val_loss: 0.4319 - val_dice_coeff: 0.5681\n","\n","Epoch 00020: val_loss improved from 0.44034 to 0.43185, saving model to model.h5\n","Epoch 21/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3915 - dice_coeff: 0.6085 - val_loss: 0.4211 - val_dice_coeff: 0.5789\n","\n","Epoch 00021: val_loss improved from 0.43185 to 0.42111, saving model to model.h5\n","Epoch 22/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3822 - dice_coeff: 0.6178 - val_loss: 0.4202 - val_dice_coeff: 0.5798\n","\n","Epoch 00022: val_loss improved from 0.42111 to 0.42018, saving model to model.h5\n","Epoch 23/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3798 - dice_coeff: 0.6202 - val_loss: 0.4222 - val_dice_coeff: 0.5778\n","\n","Epoch 00023: val_loss did not improve from 0.42018\n","Epoch 24/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3734 - dice_coeff: 0.6266 - val_loss: 0.4136 - val_dice_coeff: 0.5864\n","\n","Epoch 00024: val_loss improved from 0.42018 to 0.41355, saving model to model.h5\n","Epoch 25/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3653 - dice_coeff: 0.6347 - val_loss: 0.4110 - val_dice_coeff: 0.5890\n","\n","Epoch 00025: val_loss improved from 0.41355 to 0.41098, saving model to model.h5\n","Epoch 26/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3583 - dice_coeff: 0.6417 - val_loss: 0.4076 - val_dice_coeff: 0.5924\n","\n","Epoch 00026: val_loss improved from 0.41098 to 0.40763, saving model to model.h5\n","Epoch 27/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3529 - dice_coeff: 0.6471 - val_loss: 0.4082 - val_dice_coeff: 0.5918\n","\n","Epoch 00027: val_loss did not improve from 0.40763\n","Epoch 28/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3512 - dice_coeff: 0.6488 - val_loss: 0.4002 - val_dice_coeff: 0.5998\n","\n","Epoch 00028: val_loss improved from 0.40763 to 0.40025, saving model to model.h5\n","Epoch 29/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3444 - dice_coeff: 0.6556 - val_loss: 0.4003 - val_dice_coeff: 0.5997\n","\n","Epoch 00029: val_loss did not improve from 0.40025\n","Epoch 30/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3380 - dice_coeff: 0.6620 - val_loss: 0.3962 - val_dice_coeff: 0.6038\n","\n","Epoch 00030: val_loss improved from 0.40025 to 0.39620, saving model to model.h5\n","Epoch 31/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3344 - dice_coeff: 0.6656 - val_loss: 0.3916 - val_dice_coeff: 0.6084\n","\n","Epoch 00031: val_loss improved from 0.39620 to 0.39156, saving model to model.h5\n","Epoch 32/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3354 - dice_coeff: 0.6646 - val_loss: 0.3908 - val_dice_coeff: 0.6092\n","\n","Epoch 00032: val_loss improved from 0.39156 to 0.39084, saving model to model.h5\n","Epoch 33/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3278 - dice_coeff: 0.6722 - val_loss: 0.3899 - val_dice_coeff: 0.6101\n","\n","Epoch 00033: val_loss improved from 0.39084 to 0.38992, saving model to model.h5\n","Epoch 34/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3232 - dice_coeff: 0.6768 - val_loss: 0.3952 - val_dice_coeff: 0.6048\n","\n","Epoch 00034: val_loss did not improve from 0.38992\n","Epoch 35/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3216 - dice_coeff: 0.6784 - val_loss: 0.3902 - val_dice_coeff: 0.6098\n","\n","Epoch 00035: val_loss did not improve from 0.38992\n","Epoch 36/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3145 - dice_coeff: 0.6855 - val_loss: 0.3878 - val_dice_coeff: 0.6122\n","\n","Epoch 00036: val_loss improved from 0.38992 to 0.38777, saving model to model.h5\n","Epoch 37/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3126 - dice_coeff: 0.6874 - val_loss: 0.3857 - val_dice_coeff: 0.6143\n","\n","Epoch 00037: val_loss improved from 0.38777 to 0.38568, saving model to model.h5\n","Epoch 38/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3087 - dice_coeff: 0.6913 - val_loss: 0.3870 - val_dice_coeff: 0.6130\n","\n","Epoch 00038: val_loss did not improve from 0.38568\n","Epoch 39/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3074 - dice_coeff: 0.6926 - val_loss: 0.3823 - val_dice_coeff: 0.6177\n","\n","Epoch 00039: val_loss improved from 0.38568 to 0.38228, saving model to model.h5\n","Epoch 40/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3024 - dice_coeff: 0.6976 - val_loss: 0.3848 - val_dice_coeff: 0.6152\n","\n","Epoch 00040: val_loss did not improve from 0.38228\n","Epoch 41/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.3003 - dice_coeff: 0.6997 - val_loss: 0.3870 - val_dice_coeff: 0.6130\n","\n","Epoch 00041: val_loss did not improve from 0.38228\n","Epoch 42/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.2998 - dice_coeff: 0.7002 - val_loss: 0.3846 - val_dice_coeff: 0.6154\n","\n","Epoch 00042: val_loss did not improve from 0.38228\n","Epoch 43/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.2980 - dice_coeff: 0.7020 - val_loss: 0.3839 - val_dice_coeff: 0.6161\n","\n","Epoch 00043: val_loss did not improve from 0.38228\n","Epoch 44/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.2928 - dice_coeff: 0.7072 - val_loss: 0.3814 - val_dice_coeff: 0.6186\n","\n","Epoch 00044: val_loss improved from 0.38228 to 0.38142, saving model to model.h5\n","Epoch 45/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.2891 - dice_coeff: 0.7109 - val_loss: 0.3778 - val_dice_coeff: 0.6222\n","\n","Epoch 00045: val_loss improved from 0.38142 to 0.37781, saving model to model.h5\n","Epoch 46/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.2853 - dice_coeff: 0.7147 - val_loss: 0.3777 - val_dice_coeff: 0.6223\n","\n","Epoch 00046: val_loss improved from 0.37781 to 0.37769, saving model to model.h5\n","Epoch 47/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.2838 - dice_coeff: 0.7162 - val_loss: 0.3786 - val_dice_coeff: 0.6214\n","\n","Epoch 00047: val_loss did not improve from 0.37769\n","Epoch 48/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.2811 - dice_coeff: 0.7189 - val_loss: 0.3801 - val_dice_coeff: 0.6199\n","\n","Epoch 00048: val_loss did not improve from 0.37769\n","Epoch 49/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.2793 - dice_coeff: 0.7207 - val_loss: 0.3756 - val_dice_coeff: 0.6244\n","\n","Epoch 00049: val_loss improved from 0.37769 to 0.37556, saving model to model.h5\n","Epoch 50/50\n","1976/1976 [==============================] - 5s 3ms/step - loss: 0.2772 - dice_coeff: 0.7228 - val_loss: 0.3753 - val_dice_coeff: 0.6247\n","\n","Epoch 00050: val_loss improved from 0.37556 to 0.37527, saving model to model.h5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JXfBIVWNcJit","colab_type":"text"},"source":["#Test it!\n","Now that the model is trained, we can test our segmentation tool on the test holdout cases. Note that the prediction is the probability that a pixel is object (pancreas) or not object (anything other than pancreas). We use 0.5 as the threshold for deciding Pancreas or not, though again you can adjust this if your task might view it as more valuable to include non-pancreas pixels in order to reduce the number of missed pancreas pixels.\n","Note also that we calculate the Dice Score. The Dice calculated in training is not the actual Dice score, but it is proportional (we make adjustments so it is never 0 or have a divide by 0 error), and therefore works."]},{"cell_type":"code","metadata":{"id":"nhUydpW9LIsp","colab_type":"code","outputId":"de49c587-707c-4ada-b458-d5ae3cbcfb10","executionInfo":{"status":"ok","timestamp":1574356409768,"user_tz":360,"elapsed":332582,"user":{"displayName":"Brad Erickson","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGtI8-0w18OuIRYxbe54rj6-8_71YZ04mntCh7z4M=s64","userId":"16160187475894979440"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Cell 6\n","# load our trained model\n","model.load_weights(\"./model.h5\")\n","preds_test = model.predict(test_X, verbose=1)\n","preds_test = (preds_test > 0.5).astype(np.uint8)\n","\n","def np_dice(true, pred):\n","    intersection = np.sum(true * pred)\n","    dc =(2.0 * intersection) / (np.sum(true) + np.sum(pred))\n","    return dc\n","\n","\n","print (\"=============================================================================================================\")\n","print(\"The dice score for test cases is: \", np_dice(test_Y, preds_test))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["143/143 [==============================] - 1s 4ms/step\n","=============================================================================================================\n","The dice score for test cases is:  0.5306023654533786\n"],"name":"stdout"}]}]}